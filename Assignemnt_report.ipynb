{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b475157a-2c50-4a5f-9dd0-31fc7d3ce423",
   "metadata": {},
   "source": [
    "## <Center> Detailed Report of the Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b916ee-3cc0-43d2-a145-cc37ada082a9",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "* ### KMeans_Clustering_UsingGEE Steps\n",
    "* ### Assisgnment Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d12a06-a894-4c45-ad58-ae89905a3c0c",
   "metadata": {},
   "source": [
    "### <Center> KMeans_Clustering_UsingGEE Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d8637-228d-4676-b48a-e9a0f2cb59ac",
   "metadata": {},
   "source": [
    "In this excercise, our task is to perform K-means clustering algorithm for Landuse clustering in two different countries using the Sentinel 2 imagery and functionalities of Google earth Engine. Several steps has been performed to carry out the task. The steps are discussed below along with arough flowchart for better understanding the steps."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59e375eb-54ae-444c-9ad7-7b8c7b52e8a9",
   "metadata": {},
   "source": [
    "<Center> \n",
    "  <img src=\"./images/Flowchart.jpg\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c452be0d-eecd-485d-9917-57900ba7a210",
   "metadata": {},
   "source": [
    "## 1. Import Google Earth Engine API and Initializing the authentication process\n",
    "\n",
    "This step has been carried out to import all the functionalities of Google Earth Engine in Python and the authentication step lets one to log in Google Earth Engine with one's user name and password. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890daff3-4731-4f72-9a82-5912c10f1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07182bac-bb65-4980-9627-8ec50627099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except Exception as e:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e8ed1-a29b-4064-ac3a-e6244b28b246",
   "metadata": {},
   "source": [
    "## 2. Dask\n",
    "\n",
    "As the sample dataset contains 10 CSV files, dask is used to read all the dataset at once and to minimize the processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2dabf-4559-4063-b8a2-1890b6f60320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d13aa-a80f-4617-b2f9-98fc54dd9ba3",
   "metadata": {},
   "source": [
    "## 3. Reading Sample Dataset and Reindexing\n",
    "\n",
    "As all the sample dataset CSV file has its own indexing, a reindexing method was required to create and compile it into one CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d0f82-ee00-49f2-b7e5-4a8ef7a7d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('Data/SamplesSet*.csv')\n",
    "df = df.compute()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a9db7-9d26-4b43-9d85-888540b15097",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "In this step, several exploratory data analyzing processes have been carried out.\n",
    " * **Dropping Duplicates** - To remove duplicate cells\n",
    " * **Distinct_Value_Count** - To find out the numbe rof distinct landcover classes. 5 landcover class have been found.\n",
    " * **Minimum and Maximum Latitude and Longitude Value** - To check the range of countries/geographies. In this excercise, we found from the minimum and maxium latitude and longitude that the dataset given was collected from Europe. \n",
    " * **Plotting the top 20 countries with most location from dataset** - This steps has been perfomed to check the where/which country these sample datasets mostly belong to. It helped us to choose our study area for this excercise. As in this study, we were asked to choose two countries, one of which has larger correspondence to the dataset and one has lower correspondence. We chose, **France** for higher similarity and **Poland** for Lower similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290e8ce-0203-40d5-b24d-e7646f71f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_values = df['landcover'].drop_duplicates()\n",
    "distinct_value_counts = df['landcover'].value_counts()\n",
    "min_value_lat = df['lat'].min()\n",
    "max_value_lat = df['lat'].max()\n",
    "min_value_lon = df['lon'].min()\n",
    "max_value_lon= df['lon'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b8ed4-06d0-4c4b-9629-86a1ce906335",
   "metadata": {},
   "source": [
    "## 5. Importing Bounding Box List \n",
    "\n",
    "A bounding box list of the countries has been accessed and it leads to the task of finding the bounding box where majority of the sample reference points belong to.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc4bb3-0ca0-4a94-8306-a336f77ff361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('bounding_boxes.json', 'r') as file:\n",
    "    bounding_boxes = json.load(file)\n",
    "\n",
    "def is_in_bounding_box(lat, lon, bounding_box):\n",
    "    sw = bounding_box['sw']\n",
    "    ne = bounding_box['ne']\n",
    "    return sw['lat'] <= lat <= ne['lat'] and sw['lon'] <= lon <= ne['lon']\n",
    "\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# count locations in each bounding box\n",
    "for code, box in bounding_boxes.items():\n",
    "    country_name = code\n",
    "    bounding_box = box\n",
    "    min_lat, min_lon = bounding_box['sw']['lat'], bounding_box['sw']['lon']\n",
    "    max_lat, max_lon = bounding_box['ne']['lat'], bounding_box['ne']['lon']\n",
    "    filtered_df = df[df.apply(lambda row: is_in_bounding_box(row['lat'], row['lon'], bounding_box), axis=1)]\n",
    "    count = len(filtered_df)\n",
    "    bounding_box_df = dd.from_pandas(pd.DataFrame({'Country': [country_name], 'Code': [code], 'Count': [count]}), npartitions=1)\n",
    "    dfs.append(bounding_box_df)\n",
    "\n",
    "counts_df = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce021bad-dab3-4644-a3d7-1679ec4859b7",
   "metadata": {},
   "source": [
    "## 6. Filtering the point within Bounding box of study area\n",
    "\n",
    "With this operation, the reference points has bben cropped within the bounding box for France and Poland and it is used for the accuracy assessment of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf8af0b-2873-4e24-903d-8b1c8c767692",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_latitude = 43.303\n",
    "max_latitude = 49.124\n",
    "min_longitude = -3.142\n",
    "max_longitude = 6.561\n",
    "\n",
    "# Filter points within the bounding box\n",
    "france_points_small = df[\n",
    "    (df['lat'] >= min_latitude) & \n",
    "    (df['lat'] <= max_latitude) & \n",
    "    (df['lon'] >= min_longitude) & \n",
    "    (df['lon'] <= max_longitude)\n",
    "]\n",
    "\n",
    "france_points_small = france_points_small.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48c445-f54d-43be-aa98-129b85c73b34",
   "metadata": {},
   "source": [
    "## 7. Sentinel_2 Image Access\n",
    "\n",
    "The Sentinel-2 images for Summer 2023 (from 2023-06-01 to 2023-08-30) with cloud cover below 30% have been accessed for this exercise. Here, a cloud coverage below 30% is considered sufficient as it can be compensated for by median calculation. The Google Earth Engine (GEE) Python API has been utilized, as it has a massive archive of datasets and allows direct access to these datasets without the need to download them to the local computer. This approach enhances processing efficiency and speed, while also reducing the task of manually downloading images from the server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998199d-680e-4d3f-843a-82a1ccb02a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_france = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\\\n",
    "  .filterBounds(bounding_box)\\\n",
    "  .filterDate('2023-06-01', '2023-08-30')\\\n",
    "  .filterMetadata('CLOUDY_PIXEL_PERCENTAGE', 'less_than', 30) \\\n",
    "  .sort('CLOUDY_PIXEL_PERCENTAGE', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd9f8d-3444-4f3b-a343-7625aa809c6e",
   "metadata": {},
   "source": [
    "## 8. Data Interrogotaion\n",
    "\n",
    "Here several image data interrogation steps has been perfomed to get the information about the images that have been accessed and to reduce the size of the images.\n",
    " * Number of Images\n",
    " * Band Names\n",
    " * Median Image Calculation\n",
    " * Band Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fe7b4-8a07-41d0-ade8-2e5aaaf3bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfImages = map_france.aggregate_array('system:index').getInfo()\n",
    "bandNames = median_image.bandNames() \n",
    "median_image = map_france.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78871d-ffc8-4764-9a93-019c90c8db37",
   "metadata": {},
   "source": [
    "## 9. Create Training datasets and display\n",
    "\n",
    "In this step, a training dataset has been created for the selected study area, consisting of about 10,000 pixels. The clustering occurs based on the spectral characteristics of the pixels in the feature space and their distance from the randomly initialized cluster center. For later experiments, the number of pixels has also been increased to 100,000 to check the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756ae31-40c1-4a43-b8f9-a9530b92dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = median_image.sample(**{\n",
    "    'region':bounding_box,\n",
    "    'scale': 30,\n",
    "    'numPixels': 10000,\n",
    "    'seed': 0,\n",
    "    'tileScale' : 2,\n",
    "    'geometries': True # the geometries are not included\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62587bb4-ef55-400a-ac97-02e9b690c8c6",
   "metadata": {},
   "source": [
    "## 10. Clustering and Displaying the cluster\n",
    "\n",
    "In this step, the clustering has been carried out for several numbers of clusters based on the training data previously created randomly from the satellite imagery. The result will provide an image with predefined clusters for the whole image, where each pixel belongs to that predefined cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c447c-0463-46f7-a29d-ec48fca42a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "clusterer = ee.Clusterer.wekaKMeans(n_clusters).train(training)\n",
    "\n",
    "# Cluster the input using the trained clusterer.\n",
    "result = median_image.cluster(clusterer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2e410-5623-46e6-9383-f8f3b50709fb",
   "metadata": {},
   "source": [
    "## 11. Performance Assessment\n",
    "\n",
    "To check the accuracy of the cluster based on the ground truth data from the sample dataset, this step has been performed. The result shows the inaccuracy of the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508c759-ca6f-494e-bb43-432ffeed6c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_for_coordinates(lat, lon):\n",
    "    point = ee.Geometry.Point(lon, lat)\n",
    "    cluster = result.reduceRegion(ee.Reducer.first(), point, 80)  # Adjust the scale as needed\n",
    "    return cluster.get('cluster').getInfo()\n",
    "\n",
    "france_points['cluster'] = france_points.apply(lambda row: get_cluster_for_coordinates(row['lat'], row['lon']), axis=1)\n",
    "france_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934cf1de-fc55-4926-8879-65885559443c",
   "metadata": {},
   "source": [
    "## 12. Histogram Operation \n",
    "\n",
    "A histogram operation has been performed to check the clusters and to determine how many land cover classes belong to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1860c5-5b95-4487-ba8b-fa0d01da3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = france_points.groupby(['cluster', 'landcover']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the data to create a table suitable for plotting\n",
    "pivot_data = grouped_data.pivot(index='cluster', columns='landcover', values='count').fillna(0)\n",
    "\n",
    "colors = {\n",
    "    'Water': 'blue',\n",
    "    'ForestNaturalAreas': 'green',\n",
    "    'ArtificialSurfaces': 'grey',\n",
    "    'Wetlands': 'purple',\n",
    "    'AgriculturalArea': '#FFD700'\n",
    "}\n",
    "\n",
    "# Plotting with custom colors\n",
    "pivot_data.plot(kind='bar', stacked=True, color=[colors[col] for col in pivot_data.columns])\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Points per Cluster for Each Landcover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421749d-4436-4350-a89c-11c2d9ff85fa",
   "metadata": {},
   "source": [
    "### <Center> Assignment Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2de61-5278-428d-aa33-f4e4165ed450",
   "metadata": {},
   "source": [
    "## 1. Why do we need to train an Unsupervised Classifier in GEE? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7acad-8ad1-4d7e-977a-3536f7b69720",
   "metadata": {},
   "source": [
    "\n",
    "Unlike a supervised clustering algorithm, which requires labeled training data, any machine learning clustering algorithm in Google Earth Engine requires unlabeled training data. This is simply because it has a large dataset from all over the world, and it would be difficult and challenging, due to the scale of the datasets, to perform unsupervised clustering on it. Generally, in any unsupervised task, we ask the machine to find patterns or clusters in the dataset, which is quite difficult in Earth Engine. Instead, it requires some smaller, manageable training data, and then, based on the training data, it performs clustering for the whole broader dataset for predefined cluster numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac76cbd-d870-4745-b082-77e93276d576",
   "metadata": {},
   "source": [
    "## 2. Impact of Number of Cluster in the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc67ebc-1dc3-44de-bd01-3103b7e27e0e",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"images/Pol2.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "  <img src=\"images/Pol3.png\" alt=\"Image 2\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"images/Pol4.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "  <img src=\"images/Pol5.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"images/Pol10.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "  <img src=\"images/Pol12.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af259c-dbba-45ce-8703-086e83c8308b",
   "metadata": {},
   "source": [
    "We have tried multiple numbers of clusters to check the impact on the result. Even with trying multiple numbers of clusters, we found that each cluster is a combination of several land cover classes. There are several potential reasons behind it.\n",
    "\n",
    "**Cluster Center Initialization:** In K-means, the cluster center initialization occurs randomly, and it has an influence on the rest of the clustering phase by calculating the distance from that center. We believe this creates the problem of clustering different land cover classes into one cluster.\n",
    "\n",
    "**Use of All Bands:** Generally, the Red, Green, Blue, and NIR bands are required to distinguish different land cover types as they are mostly sensitive to these bands, and their reflectance value is highly dependent on it. Due to the use of all the bands here, and each band being responsible for creating one dimension (and creating a multi-dimension eventually) where these pixels are situated, it creates a problem while calculating the distance for K-means clustering. Thus, each cluster takes all the nearby pixels even if they belong to different classes and makes one cluster. The example of what can happen if the use of bands is reduced to only 3 (B2, B3, B4) is shown below. The left figure is the map of France with all bands used, and the right one only uses the 3 mentioned ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd7c15",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"images/france_map_big.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "  <img src=\"images/map_france_less_bands.png\" alt=\"Image 2\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031cd6a-da69-4ec0-b31f-9b7e1c88418e",
   "metadata": {},
   "source": [
    "## 3. Impact of performing Cluster in different Region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142c7e4",
   "metadata": {},
   "source": [
    "The bounding box used for Poland was shifted to another area in Europe while keeping the dimensions the same. Below, the figures show the area in Poland with the output of the clustering, as well as the area of the shifted bounding box with also the output of the clustering. The training data that was used to assign points to the clusters was identical for the area of Poland and the shifted area, which means the clustering was done in a different region using trained data from another one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a789c",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"images/Pol_map_big.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "  <img src=\"images/Pol_other_map.png\" alt=\"Image 2\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd40d3a",
   "metadata": {},
   "source": [
    "As can be seen, the water in both of the pictures seems to be detected correctly. And as the second area is placed more to the south, it is understandable that other color bands prevail. However, the histograms shown below indicate that in both cases, the clustering did not manage to separate all the land covers correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4cba8",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center;\">\n",
    "  <img src=\"images/Pol5.png\" alt=\"Image 1\" style=\"width: 49%; margin: 0 10px;\">\n",
    "  <img src=\"images/Pol_Other.png\" alt=\"Image 2\" style=\"width: 49%; margin: 0 10px;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d9141",
   "metadata": {},
   "source": [
    "There are no wetlands areas in the case of the second area, which matches the geographical location of the second area. What can be seen is that different clusters have different amounts of detected points in them. Additionally, cluster 1 for the other area does not have any points that would be classified as Artificial Surfaces. This is surprising, as usually the clusters trained on one area should not necessarily perform better on the other one (which differs a lot from the original)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aff6cc-bcb3-4a6e-bfca-92de3b24dc38",
   "metadata": {},
   "source": [
    "## 4. Computational Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285db99",
   "metadata": {},
   "source": [
    "All the code was executed on a local machine; therefore, with the available resources, the time it took to train and cluster the data was not significant. See figures below.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/training_times.png\" alt=\"Image Description\" width=\"70%\">\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/clustering_times.png\" alt=\"Image Description\" width=\"70%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408bda3",
   "metadata": {},
   "source": [
    "The main bottleneck we experienced had to do with comparing the real data with the clustered one. As the function **.getInfo()** retrieves information from the server by making a request and then waits for a response. It involves communication between Crib and the Earth Engine server and it inroduces delays. The bigger or more complex the data set the longer the delay. It was observed that when dealing with smaller areas (thus smaller amount of data points and lower complexity of them) the process of comparison the clustered data with the real one went much fatser.   \n",
    "\n",
    "Below is the snippet of the code using **.getInfo()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfd5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_for_coordinates(lat, lon):\n",
    "    point = ee.Geometry.Point(lon, lat)\n",
    "    cluster = result.reduceRegion(ee.Reducer.first(), point, 80)  # Adjust the scale as needed\n",
    "    return cluster.get('cluster').getInfo()\n",
    "\n",
    "france_points['cluster'] = france_points.apply(lambda row: get_cluster_for_coordinates(row['lat'], row['lon']), axis=1)\n",
    "france_points.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
